{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c70b0d2-f708-4e13-8321-1c05658d3459",
   "metadata": {},
   "source": [
    "# MUM 2023-24 Funkcje kosztu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12547753-b8a3-4294-b174-ef3bfaeb9cd9",
   "metadata": {},
   "source": [
    "## Funkcja kosztu (cost function, loss function, error function)\n",
    "<img style=\"float: left;\" src=\"ml_figures/mse-l1-huber.png\" width=480>\n",
    "\n",
    "* standardowo uczymy sieci neuronowe algorytmami gradientowymi\n",
    "  * musimy podać cel optymalizacji, a funkcja go opisująca potrzebuje  być różniczkowalna\n",
    "  * funkcja kosztu musi łączyć wszystkie cele w postaci wartości liczbowej, ew. wektora, co pozwoli na porównanie różnych alternatywnych możliwości rozwiązania\n",
    "  * funkcja kosztu musi odpowiadać zadaniu\n",
    "  * funkcja powinna mapować rozwiązania na gładką powierzchnię w przestrzeni rozwiązań\n",
    "    * dla danego problemu i danej architektury, przestrzeń wag i przestrzeń\n",
    "* podstawy podejść do uczenia w notebookach\n",
    "   * [Twierdzenie Bayesa](./stat_04_Twierdzenie_Bayesa.ipynb)\n",
    "   * oraz [Regularyzacja](24_Regularyzacja.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e518b75-557d-4f0b-928e-02acbbd18056",
   "metadata": {},
   "source": [
    "## Problemy regresji w uczeniu MLE\n",
    "<img style=\"float: right;\" src=\"ml_figures/classification-multi.png\" width=40>\n",
    "\n",
    "* `nn.MSELoss()` dla kwadratu różnicy\n",
    "* `nn.L1Loss()` dla wartości bezwzględnej różnicy\n",
    "* **uwaga**: poniżej wszędzie $x$ odpowiada predykcji modelu, a $y$ prawdziwej (true) wartości\n",
    "* kwadrat różnicy rośnie bardzo szybko\n",
    "  * to wprowadza bardzo duże wartości dla outlierów, utrudniając uczenie i jakimś rozwiązaniem może być połączenie L2 i L1\n",
    "  * `nn.HuberLoss` \n",
    "    $$l_k=\\begin{cases}\n",
    "    0.5*(x_k-y_k)^2&if\\;|x_k-y_k|<\\delta\\\\\n",
    "    \\delta*(|x_k-y_k|-0.5*\\delta)\n",
    "    \\end{cases}$$ (dla $\\delta=1$ równoważne `nn.SmoothL1Loss`)\n",
    "  * `nn.SmoothL1Loss`\n",
    "  $$l_k=\\begin{cases}\n",
    "    0.5*(x_k-y_k)^2/\\beta&if\\;|x_k-y_k|<\\beta\\\\\n",
    "    |x_k-y_k|-0.5*\\beta\n",
    "    \\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecba563-4d31-4709-804b-345790589fa2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Problemy klasyfikacji w MLE\n",
    "* dla MLE zwykle _entropię krzyżową_\n",
    "  * mierzy całkowitą entropię między rozkładami: rozkładem danych i rozkładem predykcji\n",
    "* `nn.CrossEntropyLoss()` $l_k=-\\dfrac{\\exp(x_{x_k, y_k})}{\\sum_c\\exp(x_{k,c})}\\cdot{}y_k$ dla $y_k\\in\\{0,1\\}$\n",
    "  * $x$ są **logitami** (indeks $k$ jest indeksem przykładu w batchu)\n",
    "* `nn.BCELoss` mierzy binarną entropię krzyżową $l_k=-\\big(y_k\\log{}x_k+(1-y_k)\\log(1-x_k)\\big)$\n",
    "  * `nn.BCELoss` obcina wartości tak by $log()\\geq-100$\n",
    "* `nn.BCEWithLogitsLoss` $l_k=-\\big(y_k\\log{}\\sigma(x_k)+(1-y_k)\\log(1-\\sigma(x_k))\\big)$\n",
    "  * funkcja *sigmoidalna* $\\sigma()$ poprawia numeryczną stabilność przez działanie na logitach\n",
    "* `nn.NLLLoss` jest wygodna dla wieloklasowej klasyfikacji (C klas) $l_k=-x_k$\n",
    "  * odpowiednik logarytmu *eksponencjalnej* funkcji kosztu $\\exp(-x_ky_k)$ dla $y\\in\\{0, 1\\}$\n",
    "\n",
    "<img style=\"float: left;\" src=\"ml_figures/loss-robustness.png\" width=480>\n",
    "\n",
    "* zwykle można dodać wagi do przykładów/klas by poprawić trade-off precision-recall, a także gdy zbiór jest niezbalansowany"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a114e047-790c-4e46-a01b-11d82ec04016",
   "metadata": {},
   "source": [
    "## i wiele innych\n",
    "* `nn.KLDivLoss` wykorzystująca dywergencję Kullback-Leiblera\n",
    "  * KL mierzy ile bitów potrzeba aby rozkład $P$ opisać rozkładem $Q$ (niesymetryczna)\n",
    "* dla problemów uczenia kontrastowego\n",
    "* dla zadań gdy mamy więcej niż jedną prawdziwą pozycję wektora odpowiedzi\n",
    "  * w problemach *multi-class* wektor ma jedną wartość $1$ na poprawnej odpowiedzi, poza tym zera\n",
    "  * w problemach *multi-label* odpowiedzi poprawnych może być więcej"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
