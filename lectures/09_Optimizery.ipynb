{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MUM 2023-24 Optymalizator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## SieÄ‡ neuronowa (NN)\n",
    "<img style=\"float: right;\" src=\"ml_figures/simple_nn.png\" width=450>\n",
    "\n",
    "* NN jest wielowymiarowÄ… funkcjÄ… (zwykle) nieliniowÄ… $F:X\\longrightarrow Y$\n",
    "  * dla funkcji zdefiniowana jest rÃ³Å¼niczkowalna funkcja kosztu $L:Y\\times F(X)\\longrightarrow \\mathbb{R}$\n",
    "  * uczenie odbywa siÄ™ w pÄ™tli dla optymalizacji parametrÃ³w\n",
    "  * problem MNIST (niespecjalnie dobre rozwiÄ…zanie!)\n",
    "* w Pytorch sieÄ‡ neuronowa jest zrealizowana jako [__graf obliczeniowy__](./12_Graf_obliczen.ipynb)\n",
    "<img style=\"float: right;\" src=\"ml_figures/comp_graph.png\" width=400>\n",
    "\n",
    "```python\n",
    "class NeuralNetwork(nn.Module):    \n",
    "    # (kod ze tutoriala `Pytorch`)\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "```\n",
    "  * do tego metoda `forward` obliczajÄ…ca wartoÅ›Ä‡ aktywacji\n",
    "```python\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "```\n",
    "  * `model = NeuralNetwork()` utworzy obiekt tej sieci\n",
    "  * pÄ™tla uczÄ…ca\n",
    "  ```python\n",
    "  def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "  ```\n",
    "  * i wykonanie\n",
    "  ```python\n",
    "  loss_fn = nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "  epochs = 10\n",
    "  for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "  ```\n",
    "  * funkcja kosztu `loss_fn` musi braÄ‡ pod uwagÄ™, jakie wartoÅ›ci zwracane sÄ… przez model\n",
    "    * tutaj model zwraca `logits` z przedziaÅ‚u $[-\\infty, +\\infty]$, stÄ…d `CrossEntropyLoss(x, y)`\n",
    "    $$L(x, y) = -\\sum_k\\log\\frac{\\exp x_k}{\\sum_i\\exp x_i}y_k$$\n",
    "  * predykcja modelu\n",
    "    ```python\n",
    "    logits = model(X)\n",
    "    pred_proba = nn.Softmax(dim=1)(logits)\n",
    "    y_pred = pred_proba.argmax(1)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Gradientowa__ i __iteracyjna__ minimalizacja $L$\n",
    "* $w$ - wektor wszystkich parametrÃ³w modelu rozpoczynajÄ…c od $w_0$\n",
    "* $w_t$ - wartoÅ›Ä‡ parametrÃ³w po $t$ krokach (po czasie $t$)\n",
    "* krok w czasie $t$ $\\Delta _t := w_t-w_{t-1}$\n",
    "* $L$ - _rÃ³Å¼niczkowalna_ funkcja kosztu\n",
    "* $\\gamma$ - __learning rate__\n",
    "    * kontroluje szybkoÅ›Ä‡ uczenia\n",
    "    * moÅ¼e zmieniaÄ‡ siÄ™ w czasie $\\gamma_t$\n",
    "* WartoÅ›Ä‡ $L$ zaleÅ¼y od:\n",
    "  * danych treningowych i wektora $\\theta$\n",
    "  * architektury modelu\n",
    "  * byÄ‡ moÅ¼e jeszcze innych staÅ‚ych\n",
    "* Optymalizujemy tylko $w$, bÄ™dziemy pisaÄ‡ w skrÃ³cie $L(w_t)$.\n",
    "* $L$ zwraca wartoÅ›Ä‡: zakÅ‚adamy, Å¼e umiemy policzyÄ‡ gradient $\\nabla L(w)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # MateriaÅ‚y dodatkowe -->\n",
    "\n",
    "<!-- http://ruder.io/optimizing-gradient-descent/index.html -->\n",
    "<!--  -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ˜Gradient Descent\n",
    "\n",
    "### Update\n",
    "<img style=\"float: right;\" src=\"ml_figures/Optimizery_steepest_descent.png\" width=400>\n",
    "\n",
    "1. $w_{t+1}=\\theta_{t} - \\gamma\\nabla L(w_{t})$\n",
    "2. $-\\nabla L(w_t)$ to kierunek najszybszego spadku $L$\n",
    "  * jednak $-\\nabla L(w_t)$ __nie wskazuje__ optymalnego kierunku $w$\n",
    "3. wektor gradientu $\\nabla L(w_t)$ jest prostopadÅ‚y do hiperpÅ‚aszczyzny stycznej do powierzchni o rÃ³wnych wartoÅ›ciach funkcji kosztu (_isosurface_) w miejscu $w_t$\n",
    "4. zmniejszenie $L$ odpowiada __co najmniej__ rozwartemu kÄ…towi miÄ™dzy $\\nabla\\theta^{(t)}$ a $\\Delta\\theta^{(t)}$\n",
    "5. learning rate $\\gamma$\n",
    "    * maÅ‚a wartoÅ›Ä‡ â€” spowalnia uczenie\n",
    "    * duÅ¼a wartoÅ›Ä‡ â€” powoduje __oscylacje__, problem ze zbieÅ¼noÅ›ciÄ…\n",
    "6. dlaczego nie normalizujemy $\\nabla L(w_t)$?\n",
    "    * duÅ¼a wartoÅ›Ä‡ gradientu to __duÅ¼a lokalna zmiennoÅ›Ä‡ $L$__ - powinniÅ›my robiÄ‡ __mniejsze kroki__ (precyzyjniej)\n",
    "    * maÅ‚a wartoÅ›Ä‡ gradientu to __maÅ‚a lokalna zmiennoÅ›Ä‡ $L$__ - powinniÅ›my robiÄ‡ __wiÄ™ksze kroki__ (aby szybciej opuÅ›ciÄ‡ __plateau__)\n",
    "7. wariant GD ze zmiennym w czasie $\\gamma$\n",
    "  * malejÄ…cy w stosunku odwrotnym do kroku uczenia $t$\n",
    "    * warunki konieczne osiÄ…gniÄ™cia optymalnego $\\gamma$ (przy jakich zaÅ‚oÅ¼eniach? uwaga na __lokalne minima__)\n",
    "        $$\\begin{align}\\sum_t\\gamma_t^2\\lt\\infty\\\\\\sum_t\\gamma_t=\\infty\\end{align}$$\n",
    "8. niech $\\gamma_{opt}$ bÄ™dzie _optymalna_\n",
    "  * $\\gamma<\\gamma_{opt}$: uczenie bÄ™dzie postÄ™powaÄ‡ zbyt maÅ‚ymi krokami\n",
    "  * $\\gamma=\\gamma_{opt}$: uczenie powinno byÄ‡ jednokrokowe (funkcja $L$ wypukÅ‚a)\n",
    "  * $\\gamma>\\gamma_{opt}$: duÅ¼e oscylacje uczenia jednak zbieÅ¼ne do minimum\n",
    "  * $\\gamma\\geq2\\gamma_{opt}$: niebezpieczeÅ„stwo wyskoczenia i rozbieÅ¼noÅ›ci w uczeniu\n",
    "9. zwykle jednak w praktyce najszybsza zbieÅ¼noÅ›Ä‡ jest osiÄ…gana przy $\\gamma$ bliskim tej dla rozbieÅ¼noÅ›ci\n",
    "  * naleÅ¼y uÅ¼ywaÄ‡ jak najwiÄ™kszej $\\gamma$ ale nie wiÄ™kszej ;-)\n",
    "\n",
    "__GD jest najgorszÄ… moÅ¼liwÄ… metodÄ… optymalizacji__ ğŸ˜ ğŸ˜’ ğŸ˜© ğŸ˜’ ğŸ˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic gradient descent SGD\n",
    "$$w_{t+1}=w_t-\\gamma_t\\nabla{}L_i(w_t)$$\n",
    "gdzie indeks $i$ wskazuje na wybrany losowo przykÅ‚ad (z rozkÅ‚adu rÃ³wnomiernego)\n",
    "* to __najlepsza metoda optymalizacji__ dlaczego?!?!\n",
    "* moÅ¼na spojrzeÄ‡ na SGD jako GD z szumem\n",
    "  * przy uczeniu wielu przykÅ‚adÃ³w jest duÅ¼y stopieÅ„ _redundancji_ przykÅ‚adÃ³w, chociaÅ¼by wiele tych samych cyfr w MNIST\n",
    "  * w poczÄ…tkowych krokach szum jest niewielki w porÃ³wnaniu do informacji w gradiencie\n",
    "    * krok SGD jest rÃ³wnie dobry jak krok GD\n",
    "  * szum moÅ¼e zabezpieczyÄ‡ przed wpadniÄ™ciem do lokalnego (niepoprawnego) minimum\n",
    "    * to przypomina _annealing_ - uczenie z _explicite_ dodanym stochastycznym szumem malejÄ…cym wraz z postÄ™pem uczenia\n",
    "  * SGD jest drastycznie szybsze od GD i moÅ¼na wykonaÄ‡ tym samym kosztem tysiÄ…ce krokÃ³w zamiast jednego kroku GD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperparametr staÅ‚ej uczenia\n",
    "* optymalna wartoÅ›Ä‡ staÅ‚ej uczenia zaleÅ¼y od wielkoÅ›ci zbioru uczÄ…cego,\n",
    "* a takÅ¼e od od wielkoÅ›ci batchu\n",
    "\n",
    "[wizualizacja [deeplearning.ai]](https://www.deeplearning.ai/ai-notes/optimization/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini batches\n",
    "$$w_{t+1}=w_t-\\gamma_t\\frac{1}{|B_i|}\\sum_{i\\in{}B_i}\\nabla{}L_i(w_t)$$\n",
    "* istotny jest element $1/|B_i|$ \n",
    "* w oczywisty sposÃ³b moÅ¼na lepiej wykorzystaÄ‡ sprzÄ™t, w szczegÃ³lnoÅ›ci GPU\n",
    "* bardzo przydatne dla urÃ³wnoleglenia uczenia\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum\n",
    "<img style=\"float: right;\" src=\"ml_figures/momentum-nag.png\" width=450>\n",
    "\n",
    "* SGD z momentum to SGD z dodanym efektem ciÄ™Å¼kiej kuli podÄ…Å¼ajÄ…cej dotychczasowym kierunkiem\n",
    "$$\\begin{align*}\n",
    "p_{t+1} &= \\nabla L_i(w_t) + \\beta p_t\\\\\n",
    "w_{t+1}&=w_t - \\gamma{}p_{t+1}=w_t - \\gamma{}\\nabla L_i(w_t) - \\gamma\\beta{}p_t\\\\\n",
    "&\\textrm{poniewaÅ¼}\\\\\n",
    "p_t&=\\nabla L_i(w_{t-1}) + \\beta p_{t-1}\\\\\n",
    "w_t&=w_{t-1} - \\gamma{}p_t\\\\\n",
    "-\\gamma{}p_t&=w_t-w_{t-1}\\\\\n",
    "&\\textrm{stÄ…d}\\\\\n",
    "w_{t+1}&=w_t - \\gamma_t\\nabla L_i(w_t) + \\beta(w_t-w_{t-1})\n",
    "\\end{align*}$$\n",
    "gdzie ostatni skÅ‚adnik jest dodatkowy wzglÄ™dem SGD\n",
    "<img style=\"float: right;\" src=\"ml_figures/opt2.gif\" width=450>\n",
    "\n",
    "0. Krok staje siÄ™ kombinacjÄ… poprzedniego kierunku i negatywnego gradientu\n",
    "1. Analogia do kulki toczÄ…cej siÄ™ ze wzgÃ³rza, $\\beta$ to tarcie lub opÃ³r powietrza\n",
    "2. __PamiÄ™Ä‡__\n",
    "    * wzajemnie wzmacniajÄ… siÄ™ kroki w __istotnym kierunku__ i kierunek nie jest zmieniany natychmiast\n",
    "    * __oscylacje__ sÄ… tÅ‚umione i uÅ›redniajÄ… siÄ™ do maÅ‚ej wartoÅ›ci\n",
    "    * mniejsze spowolnienie na __plateau__, jeÅ›li \"kulka\" byÅ‚a rozpÄ™dzona\n",
    "3. wartoÅ›ci hiperparametru $\\beta=0.9$ lub $\\beta=0.99$ sprawdzajÄ… siÄ™ prawie zawsze\n",
    "   * zwykle zwiÄ™kszenie $\\beta$ powinno skutkowaÄ‡ _zmniejszeniem_ $\\gamma$ dla utrzymania zbieÅ¼noÅ›ci\n",
    "\n",
    "To jest ten _free lunch_, ktÃ³rego podobno niema ğŸ˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nesterov accelerated gradient NAG\n",
    "\n",
    "  * NAG jest wyjÅ›ciem o jeden krok do przodu i wziÄ™ciem wartoÅ›ci w miejscu, gdzie optymalizator dopiero siÄ™ znajdzie\n",
    "$$\\begin{align}\n",
    "p_{t+1} &= \\nabla L_i(w_t) +  \\beta{}p_t\\\\\n",
    "w_{t+1}&=w_t - \\gamma_t(\\nabla L_i(w_t)+\\beta{}p_{t+1})\\\\\n",
    "       &=w_t - \\gamma_t(1+\\beta)\\nabla L_i(w_t) - \\gamma_t\\beta^2p_t\n",
    "\\end{align}$$\n",
    "    * zgrubne oszacowanie _prawdopodobnego_ nowego $w{t+1}=w_t-\\gamma_t p_{t+1}$\n",
    "    * gradient liczony w nowym miejscu â€” rozszerzenie momentum z _ekstrapolacjÄ…_\n",
    "* wiÄ™ksze $\\beta$ powoduje wolniejszÄ… reakcjÄ™ na zmianÄ™ powierzchni bÅ‚Ä™du\n",
    "* moÅ¼na pokazaÄ‡, Å¼e NAG przyspiesza uczenie dla wypukÅ‚ych funkcji i (bardzo) dobrze dobranych parametrÃ³w\n",
    "* momentum teÅ¼ przyspiesza, ale jedynie na kwadratowych powierzchniach funkcji bÅ‚Ä™du\n",
    "* nie ma teoretycznych wynikÃ³w pokazujÄ…cych przyspieszenie NAG dla sieci neuronowych, chociaÅ¼ czÄ™sto takie obserwujemy\n",
    "  * dla sieci neuronowych zwykle NAG zachowuje siÄ™ rÃ³wnie dobrze jak momentum\n",
    "* przyspieszenie oraz wygÅ‚adzanie szumu wpÅ‚ywa na lepsze zachowanie algorytmÃ³w momentum i NAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD a Momentum a NAG\n",
    "<img style=\"float: right;\" src=\"ml_figures/opt2.gif\" width=450>\n",
    "$$\n",
    "\\begin{alignat}{5}\n",
    "w_{t+1}&=w_t-\\gamma_t\\nabla{}L_i(w_t)\\\\\n",
    "w_{t+1}&=w_t - \\gamma_t{}\\nabla L_i(w_t) + \\beta(w_t-w_{t-1})\\\\\n",
    "w_{t+1}&=w_t - \\gamma_t(1+\\beta)\\nabla L_i(w_t) - \\gamma\\beta^2p_t\n",
    "\\end{alignat}\n",
    "$$\n",
    "\n",
    "[wizualizacje algorytmÃ³w [deeplearning.ai]](https://www.deeplearning.ai/ai-notes/optimization/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
