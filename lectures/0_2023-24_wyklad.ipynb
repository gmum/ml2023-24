{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f93a77a7-750e-4f4d-9189-d8ecce34ff5f",
   "metadata": {},
   "source": [
    "# Metody uczenia maszynowego MUM 2023-24 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde0f1db-6872-4c0d-94d9-0c15fb8f89f9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Sylabus i prerekwizyty\n",
    "* Wykład obejmuje problemy uczenia sieci neuronowych, w szczególności tzw. uczenia głębokiego.\n",
    "---\n",
    "### Prerekwizyty:\n",
    "1. znajomość klasycznych metod uczenia maszynowego, przedstawianych na wykładzie prof. Spurka (zagadnienie uczenia, regresja liniowa, metody PCA, drzewa decyzyjne, lasy drzew, metody ensemblowe, etc.),\n",
    "2. podstawowa wiedza z metod algebry, analizy, statystyki (częściowo będzie wspomniane).\n",
    "---\n",
    "### Plan\n",
    "1. Wstęp i pewne założenia matematyczne\n",
    "   * będziemy wracać do tego\n",
    "2. Problem uczenia maszynowego\n",
    "   * problemy w uczeniu, zagadnienie generalizacji,\n",
    "   * jak wspomagać dobrą generalizację\n",
    "   * zadania wstępnego losowania wag oraz regularyzacji\n",
    "   * metody przeprowadzania doświadczeń\n",
    "   * statystyczne metody porównywania modeli\n",
    "4. Głębokie uczenie, podstawowe modele\n",
    "5. Modele sieci konwolucyjnych\n",
    "6. Grafowe modele\n",
    "7. Modele rekurencyjne\n",
    "8. Atencja i model transformera\n",
    "9. Uczenie generatywne\n",
    "10. Nowoczesne modele dyfuzyjne\n",
    "\n",
    "Niektóre zagadnienia mogą ulec lekkiemu przesunięciu, modyfikacji, a niektóre zagadnienia mogą być jeszcze dodane. Część może być jedynie wspomniana na wykładzie a omówiona głębiej na ćwiczeniach. Proszę się za bardzo nie przywiązywać. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1649592-f9b2-498b-b653-dc3ee50bb80f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Zasady zaliczania\n",
    "* obecność na wykładzie nie jest obowiązkowa, ale bardzo wskazana i mile widziana,\n",
    "* ćwiczenia będą się odbywały z notebook-ami Jupyter\n",
    "* językiem będzie Python, środowiskiem Pytorch\n",
    "  * tu nie ma żadnej możliwości zmiany\n",
    "* na koniec roku będzie egzamin pisemny (test wielokrotnego wyboru, kilka pytań otwartych)\n",
    "  * materiałem obowiązkowym do egzaminu jest suma materiałów wykładu i ćwiczeń\n",
    "* skala ocen jest quasi-logarytmiczna [50, 64), [64, 76), [76, 86), [86, 94), [94, 100]\n",
    "  * do końcowej oceny z przedmiotu będzie częściowo wliczana ocena z ćwiczeń\n",
    "  * piątka z ćwiczeń zwalnia z egzaminu\n",
    "* dodatkowe punkty można uzyskać za udział w jednym z projektów w grupie GMUM; ocenę będzie wyznaczał kierownik/kierowniczka danego projektu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09b1382-90a5-4043-a3a6-6df9b6a9acf8",
   "metadata": {},
   "source": [
    "## Matematyczne podstawy\n",
    "1. [Rozkłady ciągły, dyskretny i mieszany](./stat_01_Rozklad_ciagly_dyskretny_mieszany.ipynb)\n",
    "2. [Rozkłady łączny, brzegowy, i warunkowy](./stat_02_Rozklad_laczny_brzegowy_warunkowy.ipynb)\n",
    "3. [Zmienne niezależne](./stat_03_Zmienne_niezalezne.ipynb)\n",
    "4. [Twierdzenie Bayesa](./stat_04_Twierdzenie_Bayesa.ipynb)\n",
    "5. [Wartość oczekiwana, wariancja, i estymatory](./stat_05_Wartosc_oczekiwana_Wariancja_Estymatory.ipynb)\n",
    "6. [Potrzebne pojęcia z analizy i algebry](./stat_06_Analiza_i_Algebra.ipynb)\n",
    "7. [Pochodna funkcji wielu zmiennych](./stat_07_Pochodna_funkcji_wielu_zmiennych.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19f0668-6444-486c-8766-cfc4820de15a",
   "metadata": {},
   "source": [
    "## Wykład 1 \n",
    "1. [Wstęp: jakie są zagadnienia uczenia maszynowego?](./01_Wstep.ipynb)\n",
    "2. [Modele dyskryminatywne a modele generatywne](./13_Model_generatywny_vs_dyskryminatywny_Uczenie_MLE.ipynb)\n",
    "3. [Uczenie Maximum Likelihood Estimation MLE](./14_Uczenie_MLE.ipynb)\n",
    "---\n",
    "## Wykład 2\n",
    "4. [Sieci neuronowe](./28_Sieci_neuronowe.ipynb)\n",
    "---\n",
    "## Wykład 3\n",
    "5. [Zadanie klasyfikacji](./17_Klasyfikacja.ipynb)\n",
    "   * [Regresja logistyczna](20_Regresja_logistyczna_dwuklasowa.ipynb)\n",
    "   * [Regresja logistyczna dla wielu klas](21_Regresja_logistyczna_wieloklasowa.ipynb)\n",
    "6. [Zadanie regresji](./18_Regresja.ipynb)\n",
    "   * [Regresja liniowa](19_Regresja_liniowa.ipynb)\n",
    "8. [Sieci neuronowe](./28_Sieci_neuronowe.ipynb)\n",
    "9. [Niektóre funkcje kosztu sieci neuronowych](./00_Funkcje_kosztu.ipynb)\n",
    "10. [Graf obliczeń](./12_Graf_obliczen.ipynb)\n",
    "---\n",
    "12. [Gradientowe uczenie sieci neuronowych](./29_Gradientowe_uczenie_sieci_neuronowych.ipynb)\n",
    "    * [Model generatywny z rozkładem ciągłym](16_Najprostszy_model_generatywny_rozklad_ciagly.ipynb)\n",
    "    * [Model generatywny z rozkładem dyskretnym](15_Najprostszy_model_generatywny_rozklad_dyskretny.ipynb)\n",
    "13. [Optymalizacja parametrów sieci — podstawowe optymalizatory gradientowe](./09_Optimizery.ipynb)\n",
    "14. [Zaawansowana optymalizacja — optymalizatory adaptacyjne](./10_Optimizery_adaptacyjne.ipynb)\n",
    "15. [Optimizery — podsumowanie](./11_Optimizery_podsumowanie.ipynb)\n",
    "16. [Problemy generalizacji - overfitting](./23_Overfitting.ipynb)\n",
    "    * [Funkcje bazowe](./22_Funkcje_bazowe.ipynb)\n",
    "17. [Metody regularyzacji](./24_Regularyzacja.ipynb)\n",
    "18. [Zanikanie i wybuchanie gradientów - inicjalizacja oraz więcej metod regularyzacji - dropout, batchnorm](./24_Regularyzacja_plus.ipynb)\n",
    "19. [Postępowanie przy wyborze najlepszego modelu]()\n",
    "    * [Metryki dla oceny modelu](./38_Metryki.ipynb)\n",
    "    * [Ewaluacja modelu](./39_Model_evaluation.ipynb)\n",
    "    * [Wybór modelu](./40_Model_selection.ipynb)\n",
    "    * [Porównanie modeli](./41_Model_comparison.ipynb)\n",
    "22. [Modele sieci konwolucyjnych](./00_Convolutions.ipynb)\n",
    "23. [Modele typu ResNet](./00_ResNet.ipynb)\n",
    "21. [Modele grafowych sieci neuronowych GNN]()\n",
    "24. [Modele generatywne]()\n",
    "25. [Modele sieci rekurencyjnych]()\n",
    "26. [Atencja](./00_Atencja.ipynb)\n",
    "27. [Model Transformera](00_Transformer.ipynb)\n",
    "28. [Zaawansowane modele dyfuzyjne]()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
